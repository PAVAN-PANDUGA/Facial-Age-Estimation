{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329c2b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcd7094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17814.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21283.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16496.jpg</td>\n",
       "      <td>YOUNG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4487.jpg</td>\n",
       "      <td>MIDDLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   Class\n",
       "0    377.jpg  MIDDLE\n",
       "1  17814.jpg   YOUNG\n",
       "2  21283.jpg  MIDDLE\n",
       "3  16496.jpg   YOUNG\n",
       "4   4487.jpg  MIDDLE"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0c2716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>377.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17814.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21283.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Class\n",
       "0    377.jpg      1\n",
       "1  17814.jpg      0\n",
       "2  21283.jpg      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].replace(['YOUNG','MIDDLE','OLD'],[0,1,2],inplace=True)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4797bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(path,ch = 3, resize=(150,150)):\n",
    "    di = tf.io.read_file(path)\n",
    "    di = tf.image.decode_jpeg(di, channels=ch)\n",
    "    di = tf.image.convert_image_dtype(di, dtype=tf.float32)\n",
    "    di = tf.image.resize(di, resize)\n",
    "    return di"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a7bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(image_path, label):\n",
    "    img = readImage(image_path, 3, (150,150))\n",
    "    return (img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f10c378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19906\n",
      "19906\n"
     ]
    }
   ],
   "source": [
    "PATH = \"Train\"\n",
    "image_paths = []\n",
    "for path in os.listdir(PATH):\n",
    "    image_paths.append(PATH+\"/\"+path)\n",
    "print(len(image_paths))\n",
    "\n",
    "response_list = []\n",
    "\n",
    "for i in image_paths:\n",
    "    _,tail = os.path.split(i)\n",
    "    response = data.loc[data['ID'] == tail]['Class'].values[0]\n",
    "    response_list.append(response)\n",
    "print(len(response_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a24e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17915\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9*(len(image_paths)))\n",
    "print(train_size)\n",
    "test_size = int(0.1*(len(image_paths)))\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices((image_paths[:train_size], response_list[:train_size]))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((image_paths[test_size:], response_list[test_size:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d84860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = (train_set\n",
    "    .map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(64)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2505fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = (test_set\n",
    "    .map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(64)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5407f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers,models\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(filters=30, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3), padding = 'same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # layers.BatchNormalization(),\n",
    "\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    # layers.BatchNormalization(),\n",
    "    \n",
    "    # layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    # layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    # layers.Dropout(0.25),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7773335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 30)      840       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 64)        17344     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 87616)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                5607488   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 5,625,867\n",
      "Trainable params: 5,625,867\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2be3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cnn_model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef074a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "280/280 [==============================] - 369s 1s/step - loss: 0.8626 - accuracy: 0.6244 - val_loss: 0.7326 - val_accuracy: 0.6794\n",
      "Epoch 2/10\n",
      "280/280 [==============================] - 363s 1s/step - loss: 0.7262 - accuracy: 0.6829 - val_loss: 0.6700 - val_accuracy: 0.7193\n",
      "Epoch 3/10\n",
      "280/280 [==============================] - 363s 1s/step - loss: 0.6655 - accuracy: 0.7131 - val_loss: 0.6229 - val_accuracy: 0.7409\n",
      "Epoch 4/10\n",
      "280/280 [==============================] - 364s 1s/step - loss: 0.5914 - accuracy: 0.7523 - val_loss: 0.5747 - val_accuracy: 0.7631\n",
      "Epoch 5/10\n",
      "280/280 [==============================] - 364s 1s/step - loss: 0.5143 - accuracy: 0.7914 - val_loss: 0.5335 - val_accuracy: 0.7854\n",
      "Epoch 6/10\n",
      "280/280 [==============================] - 373s 1s/step - loss: 0.4448 - accuracy: 0.8223 - val_loss: 0.4876 - val_accuracy: 0.8092\n",
      "Epoch 7/10\n",
      "280/280 [==============================] - 397s 1s/step - loss: 0.3835 - accuracy: 0.8498 - val_loss: 0.5483 - val_accuracy: 0.8005\n",
      "Epoch 8/10\n",
      "280/280 [==============================] - 378s 1s/step - loss: 0.3233 - accuracy: 0.8725 - val_loss: 0.5185 - val_accuracy: 0.8177\n",
      "Epoch 9/10\n",
      "280/280 [==============================] - 370s 1s/step - loss: 0.2644 - accuracy: 0.8983 - val_loss: 0.3938 - val_accuracy: 0.8578\n",
      "Epoch 10/10\n",
      "280/280 [==============================] - 381s 1s/step - loss: 0.2287 - accuracy: 0.9105 - val_loss: 0.3960 - val_accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x220f092d080>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(train_set, epochs=10, validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8116b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"train_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09d830f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 83s 297ms/step - loss: 0.2976 - accuracy: 0.8796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2976023256778717, 0.879598081111908]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54ce5706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280/280 [==============================] - 84s 300ms/step - loss: 0.3960 - accuracy: 0.8604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3959575891494751, 0.8604041337966919]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc1631b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = cnn_model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f5be653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Predictions response sample: [0, 1, 1, 1, 1, 1, 2, 0, 1, 0]\n",
      "Test True response sample: [0, 1, 0, 0, 1, 1, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_labels = [np.argmax(item) for item in test_pred]\n",
    "print(\"Test Predictions response sample:\",y_labels[:10])\n",
    "\n",
    "test_response = response_list[test_size:]\n",
    "print(\"Test True response sample:\", test_response[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb86a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['YOUNG','MIDDLE','OLD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8ab6e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f80d2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
